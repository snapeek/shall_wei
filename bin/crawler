#!/usr/bin/env ruby

require File.expand_path("../../app/crawlers/weibo_crawl", __FILE__)
require File.expand_path("../../app/crawlers/oops_crawl", __FILE__)
require File.expand_path("../../lib/nlpir", __FILE__)

@oops = OopsCrawl.new
def weibo
  @weibo ||= WeiboCrawl.new
end

def login(username = nil, password = nil)
  # username ||= "xzwyqy@163.com"
  # password ||= "1991lamb"
  @username = username if username
  @password = password if password
  if weibo.login 
    opt = weibo.load_status
    search(opt) if opt
  end
end

def set_delay(_d)
  weibo.delay_times = _d 
end

def s(key_id, ns = 1)
  kw = Keyword.find key_id
  k = nil
  ns.times do |n|
    ttt = (kw.endtime - kw.starttime) / ns
    p (ttt*n)
    k = kw.kibers.create(
      starttime: kw.starttime + 20.hours + ttt*n,
      crdtime: kw.starttime + 20.hours + ttt*n,
      endtime: kw.starttime + 20.hours + ttt*(n+1),
      gap: 72
    )
    p k.id
  end
  # search k.id
  # binding.pry
end

def ss(key_id)
  kw = Keyword.find key_id
  k = kw.kibers.create(
    starttime: kw.starttime + 20.hours ,
    crdtime: kw.starttime + 20.hours,
    endtime: kw.endtime + 20.hours,
    gap: 120
  )
  search k.id
end

def cc(kid)
  search kid
end

def c(key_id)
  k = Keyword.find(key_id).kibers.first
  search k.id
end

def search(kid)
  k = Kiber.find(kid)
  while true
    break if k.crdtime > k.endtime
    starttime = Time.at(k.crdtime).strftime("%F-%H")
    endtime = Time.at(k.crdtime + k.gap.hours).strftime("%F-%H")
    weibo.search(
      keyword: k.keyword.content, 
      page: k.page , 
      starttime: starttime, 
      endtime: endtime, 
      xsort: false, 
      ori: true,
      kid: kid)
    k.crdtime += k.gap.hours
    k.page = 1
  end
  k.status = k.status | 4
  k.save
end

def search_all_count(keywords = nil)
  tt = Time.parse('2015-1-1')
  ts = Time.parse('2015-4-1')
  # keywords ||= Keyword.where(:starttime.gt => tt.to_i).where(:starttime.lt => ts.to_i)
  keywords ||= Keyword.where(:is_deleted => false)
  CSV.open("tmp/csv/微博提及_#{Time.now.to_i}.csv", "wb") do |csv|
    csv << ["电影","提及总数", "原创数", "转发数"]
    i = 0
    keywords.each do |k|
      r = weibo.all_count(
        keyword: k.content, 
        starttime: k.starttime,
        endtime: k.endtime
      )
      csv << [k.content,r[:total_num_all], r[:total_num_ori], (r[:total_num_all] - r[:total_num_ori] rescue 0)]
    end
  end
end

def search_every_day_count(key_id = nil)
  tt = Time.parse('2015-1-1')
  ts = Time.parse('2015-4-1')
  k = Keyword.find(key_id)
  # keywords ||= Keyword.where(:starttime.gt => tt.to_i).where(:starttime.lt => ts.to_i)
  # keywords ||= Keyword.where(:is_deleted => false)
  CSV.open("tmp/csv/微博提及_#{ k.content}_#{Time.now.to_i}.csv", "wb") do |csv|
    csv << ["日期","提及总数", "原创数", "转发数"]
    tc = (ts - tt) / 86400
    tc.to_i.times do |tn|
      r = weibo.all_count(
        keyword: k.content, 
        starttime: k.starttime + tn.days,
        endtime: k.starttime + (tn + 1).days
      )
      k.day_count = r[:total_num_all]
      k.ori_day_count = r[:total_num_ori]
      csv << [Time.at(k.starttime + tn.days).strftime("%F"),r[:total_num_all], r[:total_num_ori], (r[:total_num_all] - r[:total_num_ori] rescue 0)]
    end
  end
  k.save
end

def news(key_id)
  k = Keyword.find(key_id)
  @oops.crawl_news(k)
end

def dayc(key_id)
  key = Keyword.find(key_id)
  weibo.search_day_count(key)
end

def continue_search
  search(weibo.search_options)
end

puts "
# ==============================================
#
#       登陆      login username, password
#       搜索      search keyword | options
#       设置间隔  set_delay 3..6(default)
#       导出      export 
#       退出      ctrl + c[d] or exit!
#
# ==============================================
" 
pry